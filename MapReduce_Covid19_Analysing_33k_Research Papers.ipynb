{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce Performance Processing - Analysing 33,000 Covid-19 Research Papers\n",
    "\n",
    "Example of improving query performance by x100.\n",
    "\n",
    "How do you query 100M+ rows of Cloud data? Or find the time to read 33000 Covid-19 research papers? \n",
    "\n",
    "\n",
    "### Introducing the solution: MapReduce Multiprocessing\n",
    "\n",
    "A well established way to split your data into chunks and process it in parallel using all the processors in your system/cluster. The process goes something like this: \n",
    "\n",
    "INPUT -> SPLIT -> MAP (apply a function with multiple processors) -> REDUCE (put back together & sort) -> OUTPUT\n",
    "\n",
    "This script uses data from Kaggles \"COVID-19 Open Research Dataset Challenge (CORD-19)\" and demonstrates the power of multiprocessing. \n",
    "\n",
    "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import reduce\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try and summarise the contents of all our covid-19 research papers.\n",
    "\n",
    "First lets take a look at the data. You'll see we have 33k valid research papers listed here. \n",
    "\n",
    "With each paper we have the title, author, abstract and body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33012 entries, 0 to 33011\n",
      "Data columns (total 18 columns):\n",
      "paper_id                       33012 non-null object\n",
      "title                          29377 non-null object\n",
      "abstract                       24539 non-null object\n",
      "body_text                      33012 non-null object\n",
      "cord_uid                       30183 non-null object\n",
      "source_x                       30183 non-null object\n",
      "doi                            29877 non-null object\n",
      "pmcid                          15121 non-null object\n",
      "pubmed_id                      23212 non-null float64\n",
      "license                        30183 non-null object\n",
      "publish_time                   30183 non-null object\n",
      "authors                        29634 non-null object\n",
      "journal                        29063 non-null object\n",
      "Microsoft Academic Paper ID    296 non-null float64\n",
      "WHO #Covidence                 420 non-null object\n",
      "has_full_text                  30183 non-null object\n",
      "full_text_file                 30183 non-null object\n",
      "url                            30180 non-null object\n",
      "dtypes: float64(2), object(16)\n",
      "memory usage: 4.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_full_text</th>\n",
       "      <th>full_text_file</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25621281691205eb015383cbac839182b838514f</td>\n",
       "      <td>SMARCA2-regulated host cell factors are requir...</td>\n",
       "      <td>The human interferon (IFN)-induced MxA protein...</td>\n",
       "      <td>Influenza A viruses (IAV) are severe human pat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7db22f7f81977109d493a0edf8ed75562648e839</td>\n",
       "      <td>Recombinant Scorpine Produced Using SUMO Fusio...</td>\n",
       "      <td>Scorpine, a small cationic peptide from the ve...</td>\n",
       "      <td>The oldest known scorpions lived around 430 mi...</td>\n",
       "      <td>ymp1pj3r</td>\n",
       "      <td>PMC</td>\n",
       "      <td>10.1371/journal.pone.0103456</td>\n",
       "      <td>PMC4113386</td>\n",
       "      <td>25068263.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>Zhang, Chao; He, Xinlong; Gu, Yaping; Zhou, Hu...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>comm_use_subset</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a</td>\n",
       "      <td>The effect of inhibition of PP1 and TNFα signa...</td>\n",
       "      <td>Background: The complex interplay between vira...</td>\n",
       "      <td>The emergence of Severe Acute Respiratory Synd...</td>\n",
       "      <td>d79twl34</td>\n",
       "      <td>PMC</td>\n",
       "      <td>10.1186/s12918-016-0336-6</td>\n",
       "      <td>PMC5035469</td>\n",
       "      <td>27663205.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>2016-09-23</td>\n",
       "      <td>McDermott, Jason E.; Mitchell, Hugh D.; Gralin...</td>\n",
       "      <td>BMC Syst Biol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>comm_use_subset</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6c3e1a43f0e199876d4bd9ff787e1911fd5cfaa6</td>\n",
       "      <td>Review Article Microbial Agents as Putative In...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sjögren's syndrome (SS) is a connective tissue...</td>\n",
       "      <td>kg7c9a9h</td>\n",
       "      <td>PMC</td>\n",
       "      <td>10.1155/2019/8567364</td>\n",
       "      <td>PMC6339763</td>\n",
       "      <td>30723750.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>Talotta, Rossella; Sarzi-Puttini, Piercarlo; A...</td>\n",
       "      <td>J Immunol Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>comm_use_subset</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2ce201c2ba233a562ee605a9aa12d2719cfa2beb</td>\n",
       "      <td>A cluster of adenovirus type B55 infection in ...</td>\n",
       "      <td>Background: Human adenovirus type 55 is a re-e...</td>\n",
       "      <td>Human adenovirus (HAdV) is a common pathogen a...</td>\n",
       "      <td>sg7esn4p</td>\n",
       "      <td>PMC</td>\n",
       "      <td>10.1111/irv.12457</td>\n",
       "      <td>PMC5485872</td>\n",
       "      <td>28488368.0</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>Yi, Lina; Zou, LiRong; Lu, Jing; Kang, Min; So...</td>\n",
       "      <td>Influenza Other Respir Viruses</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>comm_use_subset</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  25621281691205eb015383cbac839182b838514f   \n",
       "1  7db22f7f81977109d493a0edf8ed75562648e839   \n",
       "2  a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a   \n",
       "3  6c3e1a43f0e199876d4bd9ff787e1911fd5cfaa6   \n",
       "4  2ce201c2ba233a562ee605a9aa12d2719cfa2beb   \n",
       "\n",
       "                                               title  \\\n",
       "0  SMARCA2-regulated host cell factors are requir...   \n",
       "1  Recombinant Scorpine Produced Using SUMO Fusio...   \n",
       "2  The effect of inhibition of PP1 and TNFα signa...   \n",
       "3  Review Article Microbial Agents as Putative In...   \n",
       "4  A cluster of adenovirus type B55 infection in ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The human interferon (IFN)-induced MxA protein...   \n",
       "1  Scorpine, a small cationic peptide from the ve...   \n",
       "2  Background: The complex interplay between vira...   \n",
       "3                                                NaN   \n",
       "4  Background: Human adenovirus type 55 is a re-e...   \n",
       "\n",
       "                                           body_text  cord_uid source_x  \\\n",
       "0  Influenza A viruses (IAV) are severe human pat...       NaN      NaN   \n",
       "1  The oldest known scorpions lived around 430 mi...  ymp1pj3r      PMC   \n",
       "2  The emergence of Severe Acute Respiratory Synd...  d79twl34      PMC   \n",
       "3  Sjögren's syndrome (SS) is a connective tissue...  kg7c9a9h      PMC   \n",
       "4  Human adenovirus (HAdV) is a common pathogen a...  sg7esn4p      PMC   \n",
       "\n",
       "                            doi       pmcid   pubmed_id license publish_time  \\\n",
       "0                           NaN         NaN         NaN     NaN          NaN   \n",
       "1  10.1371/journal.pone.0103456  PMC4113386  25068263.0   cc-by   2014-07-28   \n",
       "2     10.1186/s12918-016-0336-6  PMC5035469  27663205.0   cc-by   2016-09-23   \n",
       "3          10.1155/2019/8567364  PMC6339763  30723750.0   cc-by   2019-01-06   \n",
       "4             10.1111/irv.12457  PMC5485872  28488368.0   cc-by   2017-06-26   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                                NaN   \n",
       "1  Zhang, Chao; He, Xinlong; Gu, Yaping; Zhou, Hu...   \n",
       "2  McDermott, Jason E.; Mitchell, Hugh D.; Gralin...   \n",
       "3  Talotta, Rossella; Sarzi-Puttini, Piercarlo; A...   \n",
       "4  Yi, Lina; Zou, LiRong; Lu, Jing; Kang, Min; So...   \n",
       "\n",
       "                          journal  Microsoft Academic Paper ID WHO #Covidence  \\\n",
       "0                             NaN                          NaN            NaN   \n",
       "1                        PLoS One                          NaN            NaN   \n",
       "2                   BMC Syst Biol                          NaN            NaN   \n",
       "3                   J Immunol Res                          NaN            NaN   \n",
       "4  Influenza Other Respir Viruses                          NaN            NaN   \n",
       "\n",
       "  has_full_text   full_text_file  \\\n",
       "0           NaN              NaN   \n",
       "1          True  comm_use_subset   \n",
       "2          True  comm_use_subset   \n",
       "3          True  comm_use_subset   \n",
       "4          True  comm_use_subset   \n",
       "\n",
       "                                                 url  \n",
       "0                                                NaN  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4...  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...  \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...  \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"COVID_19_Open_Research_Dataset.csv\")\n",
    "df.dropna(subset=['abstract'])\n",
    "\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How big is this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37522171"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all the abstracts into a block of strings and then split into parts equal to however many processors i have available. \n",
    "data = df[\"abstract\"].tolist()\n",
    "data = str(data)\n",
    "n = int(len(data)/multiprocessing.cpu_count() -1 )\n",
    "parts = [data[i:i+n] for i in range(0, len(data), n)]\n",
    "\n",
    "# Words i will want to remove later because they are purely gramatical and provide little insight\n",
    "ENGLISH_STOP_WORDS = [\"nan\",\"et\",\"al\",\"i\", \"c\", \"n\",\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]\n",
    "\n",
    "#number of charaters\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 375 million characters to analyse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyse without multi-processing\n",
    "\n",
    "We're going to time how long it takes my system to convert these characters into words and sort the words by abundance - using a single processor. \n",
    "\n",
    "We have split the data into chunks and will process in series using the \"Mapper\" function and then we will bring it all back together with the \"reducer\" function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>virus</td>\n",
       "      <td>23949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>infection</td>\n",
       "      <td>17206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>viral</td>\n",
       "      <td>16839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cells</td>\n",
       "      <td>15021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>respiratory</td>\n",
       "      <td>12692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>study</td>\n",
       "      <td>12645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protein</td>\n",
       "      <td>12578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>disease</td>\n",
       "      <td>11360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>patients</td>\n",
       "      <td>8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nan</td>\n",
       "      <td>6368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1\n",
       "0                 \n",
       "virus        23949\n",
       "infection    17206\n",
       "viral        16839\n",
       "cells        15021\n",
       "respiratory  12692\n",
       "study        12645\n",
       "protein      12578\n",
       "disease      11360\n",
       "patients      8531\n",
       "nan           6368"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function is given below, multi-processing in Jupyter requires you to import your functions\n",
    "from My_Functions_covid import mapper\n",
    "\n",
    "######---------Functions--------#######\n",
    "\n",
    "# Meat of the function - cleans, filters and splits the characters into words and then finds the most common words. Performed in chunks. \n",
    "\n",
    "#def mapper(data):\n",
    "#    lower = re.sub(r'[^\\w\\s]', '', data).lower()\n",
    "#    clean_words = re.sub(r'[^a-zA-Z ]', '', lower)\n",
    "#    output = []\n",
    "#    for x in clean_words.split():\n",
    "#        if x not in ENGLISH_STOP_WORDS:\n",
    "#            output.append(x)\n",
    "#    return collections.Counter(output).most_common(10)\n",
    "\n",
    "# Brings chunks back together\n",
    "def reducer(mapped):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for x in list(mapped):\n",
    "        df = pd.DataFrame(dict(x).items())\n",
    "        dataframe = dataframe.append(df)\n",
    "    return dataframe.groupby(dataframe.columns[0]).sum().sort_values(dataframe.columns[0], ascending = False)\n",
    "\n",
    "######---------Code--------#######\n",
    "\n",
    "t0 = time.process_time()\n",
    "clean = map(mapper, parts)\n",
    "\n",
    "reduced = reducer(clean)\n",
    "t1 = time.process_time()\n",
    "\n",
    "print(t1-t0)\n",
    "reduced.sort_values(reduced.columns[0], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18 second runtime!\n",
    "\n",
    "This is a rarther poor query speed for a business application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse with multi-processing\n",
    "\n",
    "We are going to time the exact same analysis as above but this time process all the parts in parallel using multiple processors.\n",
    "\n",
    "We have split the data into chunks and will process in parallel using the \"Mapper\" function and then we will bring it all back together with the \"reducer\" function. \n",
    "\n",
    "INPUT -> SPLIT -> MAP (apply a function with multiple processors) -> REDUCE (put back together & sort) -> OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.171875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>virus</td>\n",
       "      <td>23949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>infection</td>\n",
       "      <td>17206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>viral</td>\n",
       "      <td>16839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cells</td>\n",
       "      <td>15021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>respiratory</td>\n",
       "      <td>12692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>study</td>\n",
       "      <td>12645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protein</td>\n",
       "      <td>12578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>disease</td>\n",
       "      <td>11360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>patients</td>\n",
       "      <td>8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nan</td>\n",
       "      <td>6368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1\n",
       "0                 \n",
       "virus        23949\n",
       "infection    17206\n",
       "viral        16839\n",
       "cells        15021\n",
       "respiratory  12692\n",
       "study        12645\n",
       "protein      12578\n",
       "disease      11360\n",
       "patients      8531\n",
       "nan           6368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python's mutliprocessing library allows you to create a pool of a allowable processors. \n",
    "pool = Pool(multiprocessing.cpu_count())\n",
    "\n",
    "######---------Functions--------#######\n",
    "\n",
    "# Meat of the function - cleans, filters and splits the characters into words and then finds the most common words. Performed in chunks. \n",
    "\n",
    "#def mapper(data):\n",
    "#    lower = re.sub(r'[^\\w\\s]', '', data).lower()\n",
    "#    clean_words = re.sub(r'[^a-zA-Z ]', '', lower)\n",
    "#    output = []\n",
    "#    for x in clean_words.split():\n",
    "#        if x not in ENGLISH_STOP_WORDS:\n",
    "#            output.append(x)\n",
    "#    return collections.Counter(output).most_common(10)\n",
    "\n",
    "# Brings chunks back together\n",
    "def reducer(mapped):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for x in list(mapped):\n",
    "        df = pd.DataFrame(dict(x).items())\n",
    "        dataframe = dataframe.append(df)\n",
    "    return dataframe.groupby(dataframe.columns[0]).sum().sort_values(dataframe.columns[0], ascending = False)\n",
    "\n",
    "######---------Code--------#######\n",
    "\n",
    "###### Notice how we are now telling the Mapper function to use our pool of processors\n",
    "\n",
    "t0 = time.process_time()\n",
    "clean2 = pool.map(mapper, parts)\n",
    "\n",
    "reduced2 = reducer(clean2)\n",
    "t1 = time.process_time()\n",
    "\n",
    "print(t1-t0)\n",
    "reduced2.sort_values(reduced.columns[0], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.17 second runtime!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents a 100x improvement to query performance and is an acceptable query speed for business applications. You can see why companies like Google, AWS, M&S, British Airways etc. use it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "A note on the findings from the Covid-19 papers - its clear most studies focus on virual infections of respiratory cells with around 1/3 focusing on the impact to patients. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
